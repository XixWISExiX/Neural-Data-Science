{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Packages & Set Up Data Layout\n",
    "\n",
    "## Preprocessing Information for the Given Data.\n",
    "\n",
    "A high-pass filter with a 30 Hz cut-off frequency and a power line notch filter (50 Hz) were used. All recordings are artifact-free EEG segments of 60 seconds duration. At the stage of data preprocessing, the Independent Component Analysis (ICA) was used to eliminate the artifacts (eyes, muscle, and cardiac overlapping of the cardiac pulsation). The arithmetic task was the serial subtraction of two numbers. Each trial started with the communication orally 4-digit (minuend) and 2-digit (subtrahend) numbers (e.g. 3141 and 42)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting EDF parameters from /home/joshua/Desktop/MainFolder/OuClasses/2024 Fall/Neural-Data-Science/datasets/HW2Datasets/Subject06_1.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 90999  =      0.000 ...   181.998 secs...\n",
      "Extracting EDF parameters from /home/joshua/Desktop/MainFolder/OuClasses/2024 Fall/Neural-Data-Science/datasets/HW2Datasets/Subject06_2.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 30999  =      0.000 ...    61.998 secs...\n",
      "Extracting EDF parameters from /home/joshua/Desktop/MainFolder/OuClasses/2024 Fall/Neural-Data-Science/datasets/HW2Datasets/Subject07_1.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 90999  =      0.000 ...   181.998 secs...\n",
      "Extracting EDF parameters from /home/joshua/Desktop/MainFolder/OuClasses/2024 Fall/Neural-Data-Science/datasets/HW2Datasets/Subject07_2.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 30999  =      0.000 ...    61.998 secs...\n",
      "['Fp1', 'Fp2', 'F3', 'F4', 'F7', 'F8', 'T3', 'T4', 'C3', 'C4', 'T5', 'T6', 'P3', 'P4', 'O1', 'O2', 'Fz', 'Cz', 'Pz', 'A2', 'ECG']\n",
      "['Fp1', 'Fp2', 'F3', 'F4', 'F7', 'F8', 'T3', 'T4', 'C3', 'C4', 'T5', 'T6', 'P3', 'P4', 'O1', 'O2', 'Fz', 'Cz', 'Pz', 'A2', 'ECG']\n",
      "['Fp1', 'Fp2', 'F3', 'F4', 'F7', 'F8', 'T3', 'T4', 'C3', 'C4', 'T5', 'T6', 'P3', 'P4', 'O1', 'O2', 'Fz', 'Cz', 'Pz', 'A2', 'ECG']\n",
      "['Fp1', 'Fp2', 'F3', 'F4', 'F7', 'F8', 'T3', 'T4', 'C3', 'C4', 'T5', 'T6', 'P3', 'P4', 'O1', 'O2', 'Fz', 'Cz', 'Pz', 'A2', 'ECG']\n",
      "Data Shape Before: 21 91000\n",
      "Data Shape After: 21 303 300\n",
      "Data Shape Before: 21 31000\n",
      "Data Shape After: 21 103 300\n",
      "Data Shape Before: 21 91000\n",
      "Data Shape After: 21 303 300\n",
      "Data Shape Before: 21 31000\n",
      "Data Shape After: 21 103 300\n",
      "Shape of segmented data: (812, 6300)\n",
      "Shape of labels: (812,)\n"
     ]
    }
   ],
   "source": [
    "# Let's load some packages we need (pip install mne)\n",
    "import mne\n",
    "import mne.viz\n",
    "from mne.datasets import eegbci\n",
    "from mne.io import concatenate_raws, read_raw_edf\n",
    "from mne.channels import make_standard_montage\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "# ! pip install mne\n",
    "\n",
    "# Read raw data files where each file contains a run\n",
    "files = ['../../datasets/HW2Datasets/Subject06_1.edf', '../../datasets/HW2Datasets/Subject06_2.edf', '../../datasets/HW2Datasets/Subject07_1.edf', '../../datasets/HW2Datasets/Subject07_2.edf']\n",
    "\n",
    "# Read the raw EDF files into an array\n",
    "raws = [read_raw_edf(f, preload=True) for f in files]\n",
    "\n",
    "# Loop through the array and make the following changes to the raw files\n",
    "for raw in raws:\n",
    "\n",
    "    # Rename the raw channels\n",
    "    raw.rename_channels({'EEG F3':'F3', 'EEG F4':'F4',\n",
    "                            'EEG Fp1':'Fp1', 'EEG Fp2':'Fp2', 'EEG F7':'F7', 'EEG F8':'F8',\n",
    "                            'EEG T3':'T3', 'EEG T4':'T4', 'EEG C3':'C3', 'EEG C4':'C4',\n",
    "                            'EEG T5':'T5', 'EEG T6':'T6', 'EEG P3':'P3', 'EEG P4':'P4',\n",
    "                            'EEG O1':'O1', 'EEG O2':'O2', 'EEG Fz':'Fz', 'EEG Cz':'Cz',\n",
    "                            'EEG Pz':'Pz', 'EEG A2-A1':'A2', 'ECG ECG':'ECG'})\n",
    "\n",
    "\n",
    "    # Set channel types\n",
    "    raw.set_channel_types({'ECG':'ecg'})\n",
    "\n",
    "    # Define the channel locations\n",
    "    raw.set_montage(mne.channels.make_standard_montage('standard_1020'))\n",
    "\n",
    "    # Print Raw Channel Names for double checking\n",
    "    print(raw.ch_names)\n",
    "\n",
    "# Rename the raws with more insightfull names\n",
    "subject6_background = raws[0] # Subject 6 background raw\n",
    "subject6_task = raws[1] # Subject 6 task raw\n",
    "subject7_background = raws[2] # Subject 7 background raw\n",
    "subject7_task = raws[3] # Subject 7 task raw\n",
    "\n",
    "# Function to segment data into non-overlapping windows of length 300 samples\n",
    "def segment_data(raw, window_size=300):\n",
    "    data = raw.get_data()  # Get the raw data\n",
    "    n_channels, n_samples = data.shape\n",
    "    print(\"Data Shape Before:\", n_channels, n_samples)\n",
    "    n_windows = n_samples // window_size  # Number of windows\n",
    "\n",
    "    # Reshape data into (n_channels, n_windows, window_size)\n",
    "    segmented_data = data[:, :n_windows * window_size].reshape(n_channels, n_windows, window_size)\n",
    "    print(\"Data Shape After:\", n_channels, n_windows, window_size)\n",
    "\n",
    "\n",
    "    return segmented_data\n",
    "\n",
    "\n",
    "# Segment each raw file into windows\n",
    "subject6_background_segments = segment_data(subject6_background)\n",
    "subject6_task_segments = segment_data(subject6_task)\n",
    "subject7_background_segments = segment_data(subject7_background)\n",
    "subject7_task_segments = segment_data(subject7_task)\n",
    "\n",
    "# Create labels: 0 for background, 1 for task\n",
    "subject6_background_labels = np.zeros(subject6_background_segments.shape[1])\n",
    "subject6_task_labels = np.ones(subject6_task_segments.shape[1])\n",
    "subject7_background_labels = np.zeros(subject7_background_segments.shape[1])\n",
    "subject7_task_labels = np.ones(subject7_task_segments.shape[1])\n",
    "\n",
    "# Concatenate data and labels for both subjects\n",
    "X = np.concatenate([subject6_background_segments, subject6_task_segments, \n",
    "                    subject7_background_segments, subject7_task_segments], axis=1)\n",
    "\n",
    "y = np.concatenate([subject6_background_labels, subject6_task_labels,\n",
    "                    subject7_background_labels, subject7_task_labels])\n",
    "\n",
    "# Reshape the data for model training (n_samples, n_features)\n",
    "X = X.reshape(X.shape[1], -1)  # (n_windows, n_channels * window_size)\n",
    "\n",
    "# X shape will be (n_channels, total_windows * window_size), and y will be the labels for each window\n",
    "print(\"Shape of segmented data:\", X.shape)\n",
    "print(\"Shape of labels:\", y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q4) \n",
    "## Repeat the analysis in (Q3) using a different machine learning algorithm of your choice (other than logistic regression), and discuss how your results have changed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
